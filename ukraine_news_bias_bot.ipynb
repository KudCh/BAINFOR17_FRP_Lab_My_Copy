{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1oftX6QCPkC_vuiDZhow_mawzCIpoh66a",
      "authorship_tag": "ABX9TyP/bmC6Tr1ra6ILeeXKZvnV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KudCh/BAINFOR17_FRP_Lab_My_Copy/blob/master/ukraine_news_bias_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPLZD3Oio7bL"
      },
      "outputs": [],
      "source": [
        "from torchtext.models import T5Transform\n",
        "\n",
        "padding_idx = 0\n",
        "eos_idx = 1\n",
        "max_seq_len = 512\n",
        "t5_sp_model_path = \"https://download.pytorch.org/models/text/t5_tokenizer_base.model\"\n",
        "\n",
        "transform = T5Transform(\n",
        "    sp_model_path=t5_sp_model_path,\n",
        "    max_seq_len=max_seq_len,\n",
        "    eos_idx=eos_idx,\n",
        "    padding_idx=padding_idx,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.models import T5_BASE_GENERATION\n",
        "import torch\n",
        "\n",
        "\n",
        "t5_base = T5_BASE_GENERATION\n",
        "transform = t5_base.transform()\n",
        "model = t5_base.get_model()\n",
        "#model.cuda()\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWnlqIF51mxX",
        "outputId": "7d5f0e9a-a0ad-4404-8c3c-1cb6f90d33cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Model(\n",
              "  (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
              "  (encoder): T5Encoder(\n",
              "    (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): T5Layer(\n",
              "        (self_attn): T5MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
              "          (relative_attention_bias): Embedding(32, 12)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (norm1): T5LayerNorm()\n",
              "        (norm2): T5LayerNorm()\n",
              "        (dropout1): Dropout(p=0.0, inplace=False)\n",
              "        (dropout2): Dropout(p=0.0, inplace=False)\n",
              "        (dropout3): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (1-11): 11 x T5Layer(\n",
              "        (self_attn): T5MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (norm1): T5LayerNorm()\n",
              "        (norm2): T5LayerNorm()\n",
              "        (dropout1): Dropout(p=0.0, inplace=False)\n",
              "        (dropout2): Dropout(p=0.0, inplace=False)\n",
              "        (dropout3): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): T5LayerNorm()\n",
              "    (dropout1): Dropout(p=0.0, inplace=False)\n",
              "    (dropout2): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Decoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): T5Layer(\n",
              "        (self_attn): T5MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
              "          (relative_attention_bias): Embedding(32, 12)\n",
              "        )\n",
              "        (cross_attn): T5MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
              "        )\n",
              "        (norm3): T5LayerNorm()\n",
              "        (dropout4): Dropout(p=0.0, inplace=False)\n",
              "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (norm1): T5LayerNorm()\n",
              "        (norm2): T5LayerNorm()\n",
              "        (dropout1): Dropout(p=0.0, inplace=False)\n",
              "        (dropout2): Dropout(p=0.0, inplace=False)\n",
              "        (dropout3): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (1-11): 11 x T5Layer(\n",
              "        (self_attn): T5MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
              "        )\n",
              "        (cross_attn): T5MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
              "        )\n",
              "        (norm3): T5LayerNorm()\n",
              "        (dropout4): Dropout(p=0.0, inplace=False)\n",
              "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (norm1): T5LayerNorm()\n",
              "        (norm2): T5LayerNorm()\n",
              "        (dropout1): Dropout(p=0.0, inplace=False)\n",
              "        (dropout2): Dropout(p=0.0, inplace=False)\n",
              "        (dropout3): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): T5LayerNorm()\n",
              "    (dropout1): Dropout(p=0.0, inplace=False)\n",
              "    (dropout2): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.prototype.generate import GenerationUtils\n",
        "\n",
        "sequence_generator = GenerationUtils(model)"
      ],
      "metadata": {
        "id": "q-HkBdeX1tb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "We wanna ~~create a datapipe~~ preprocess the dataset, create a custom Pytorch dataset and then create a dataloader from it"
      ],
      "metadata": {
        "id": "WnuTo6qO147p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"average\""
      ],
      "metadata": {
        "id": "ExqDo-gVkTut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ukraine-news-bias-dataset/subjectivity_{}.csv\".format(dataset_name))\n",
        "\n",
        "# 2 classes:\n",
        "# 0 - objective, 1 - subjective\n",
        "# average: < 1, >= 1\n",
        "# majority: < 0.5, >= 0.5\n",
        "# intensified: < 0.5, >= 0.5\n",
        "limit = None\n",
        "if dataset_name == \"average\":\n",
        "    limit = 1.0\n",
        "else:\n",
        "    limit = 0.5\n",
        "data[\"labels\"] = np.where(data[\"scores\"] < limit, 0, 1)\n",
        "\n",
        "# --- preparing data for training---\n",
        "X = pd.DataFrame(data.sentences)\n",
        "y = pd.DataFrame(data.labels)\n",
        "\n",
        "# set aside 20% of train and test data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2, shuffle=True,\n",
        "                                                    random_state=8)  # 20% for testing and validation\n",
        "\n",
        "data = data[[\"sentences\", \"labels\"]]\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "validation, test = train_test_split(test, test_size=0.5)"
      ],
      "metadata": {
        "id": "nu9u3i1jfAO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepend prefixes to data\n",
        "prefix = [\"binary classification\" for i in range(len(data))]\n",
        "data[\"prefix\"]=prefix\n",
        "df = data.rename(columns={\"sentences\": \"input_text\", \"labels\": \"target_text\"})\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "validation, test = train_test_split(test, test_size=0.5)"
      ],
      "metadata": {
        "id": "0NNMjWYufJSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'\n",
        "import portalocker\n",
        "from functools import partial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMxFyn8XflAX",
        "outputId": "e4062366-b6e9-476a-ef3f-35deea37fb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def apply_prefix(task, x):\n",
        "        return f\"{task}: \" + x\n",
        "\n",
        "    def label_to_text(label):\n",
        "        return str(label)\n",
        "\n",
        "    def __init__(self, data, task, transform=apply_prefix, target_transform=label_to_text):\n",
        "        #self.img_labels = pd.read_csv(annotations_file)\n",
        "        #self.img_dir = img_dir\n",
        "        self.sentences = data[\"input_text\"].values\n",
        "        self.labels = data[\"target_text\"].values\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.task = task\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "      \n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            sentence = self.transform(self.task, sentence)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        pipe = {\"sentence\":sentence, \"label\":label}\n",
        "        return pipe"
      ],
      "metadata": {
        "id": "KrRtdxaIY4FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = MyDataset(train, task=\"binary classification\")\n",
        "# apply ToTensor() as transform\n",
        "\n",
        "validation_data = MyDataset(validation, task=\"binary classification\")\n",
        "test_data = MyDataset(test, task=\"binary classification\")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=5, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "q5ofU6amj28H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "input_text = batch[\"sentence\"]\n",
        "target = batch[\"label\"]\n",
        "beam_size = 1\n",
        "data_batch_size = 5\n",
        "\n",
        "model_input = transform(input_text)\n",
        "model_output = sequence_generator.generate(model_input, eos_idx=eos_idx, num_beams=beam_size)\n",
        "output_text = transform.decode(model_output.tolist())\n",
        "\n",
        "for i in range(data_batch_size):\n",
        "    print(f\"Example {i+1}:\\n\")\n",
        "    print(f\"input_text: {input_text[i]}\\n\")\n",
        "    print(f\"prediction: {output_text[i]}\\n\")\n",
        "    print(f\"target: {target[i]}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4zvaSxclIG7",
        "outputId": "04dd33ab-0caa-414a-8c38-726d889ba02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchtext.prototype.generate:`max_length` was not specified. Defaulting to 256 tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "\n",
            "input_text: binary classification: They include use of force, economic and propaganda pressure, meddling in domestic affairs, and appeals to a kind of ‘supra-legal’ legitimacy when they need to justify illegal intervention in this or that conflict or toppling inconvenient regimes.\n",
            "\n",
            "prediction: a number of reasons for using force include meddling in domestic affairs, economic and propaganda pressure, meddling in this or that conflict or toppling inconvenient regimes\n",
            "\n",
            "target: 0\n",
            "\n",
            "\n",
            "Example 2:\n",
            "\n",
            "input_text: binary classification: Yet caution should be exercised in using this number, because all active members do not belong to units that have trained together, although their commitment to defend their country can be assumed to be high.\n",
            "\n",
            "prediction: - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million \n",
            "\n",
            "target: 1\n",
            "\n",
            "\n",
            "Example 3:\n",
            "\n",
            "input_text: binary classification: Ukraine’s legitimate president, Viktor Yanukovich, was ousted in a violent uprising in February.\n",
            "\n",
            "prediction: \n",
            "\n",
            "target: 0\n",
            "\n",
            "\n",
            "Example 4:\n",
            "\n",
            "input_text: binary classification: The accusations went as far as to claim that Moscow sent troops and weapons to help the independence militias.\n",
            "\n",
            "prediction: False\n",
            "\n",
            "target: 0\n",
            "\n",
            "\n",
            "Example 5:\n",
            "\n",
            "input_text: binary classification: Pro-Russian separatists Wednesday exited three towns on the outskirts of the eastern city of Donetsk and areas surrounding the airport...\n",
            "\n",
            "prediction: False\n",
            "\n",
            "target: 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/drive/MyDrive/ukraine-news-bias-dataset/outputs.txt\", \"w\")\n",
        "f.write('target')\n",
        "for i in target:\n",
        "    f.write(i+'\\n')\n",
        "f.write('output')\n",
        "for i in output_text:\n",
        "    f.write(i)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "U24ARDtJW7L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "ACEB6xbQvhlH",
        "outputId": "5cca1bc0-19e5-4468-86bf-a4c0ca23515b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
            "['a number of reasons for using force include meddling in domestic affairs, economic and propaganda pressure, meddling in this or that conflict or toppling inconvenient regimes', '- 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million - 1 million ', '', 'False', 'False', '', 'False', 'a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone wolf - a lone', 'False', '- Unknown to me, but I am not sure if this is a good thing.', '- 10:55 - Russia\\'s Foreign Ministry has called on Western powers to give up their \"destructive\" policy on Ukraine.', 'a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.s. a.', 'a) Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) - Unified communications system (CDS) -', '', '', 'False']\n"
          ]
        }
      ]
    }
  ]
}